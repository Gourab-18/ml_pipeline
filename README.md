# Tabular ML Pipeline - Customer Churn Prediction

A production-ready Machine Learning pipeline for tabular data with comprehensive preprocessing, multiple model architectures, cross-validation, calibration, explainability, and REST API serving.

---

## ðŸŽ¯ Project Overview

â€¢ **Problem**: Binary classification for customer churn prediction
â€¢ **Target**: Predict probability that customer will churn within 30 days
â€¢ **Architecture**: Flexible pipeline supporting ANN (TensorFlow), XGBoost, and LightGBM baselines
â€¢ **Status**: Production-ready with complete ML lifecycle support

---

## âœ¨ Core Features

### Data & Preprocessing
â€¢ **Fold-safe preprocessing pipeline** - Prevents data leakage in cross-validation
â€¢ **Lightweight preprocessing** - Fast sklearn-only pipeline (no TensorFlow dependency)
â€¢ **Feature-specific transformations** - Scale, one-hot, embedding strategies per feature
â€¢ **Data contract compliance** - Temporal splits, label latency handling
â€¢ **Schema validation** - YAML-based schema with type checking

### Models
â€¢ **Tabular ANN** - Neural network with embeddings for categoricals, configurable MLP trunk
â€¢ **XGBoost baseline** - Gradient boosting with same CV splits
â€¢ **LightGBM baseline** - Fast gradient boosting alternative
â€¢ **Calibration support** - Platt scaling and Isotonic regression for probability calibration
â€¢ **Model comparison** - Side-by-side metrics (ROC-AUC, PR-AUC, Brier, ECE)

### Training & Evaluation
â€¢ **K-Fold cross-validation** - Reproducible splits with per-fold artifacts
â€¢ **Nested CV with HPO** - Optional inner-loop hyperparameter optimization
â€¢ **OOF predictions** - Out-of-fold predictions for unbiased evaluation
â€¢ **Comprehensive metrics** - ROC-AUC, PR-AUC, Brier score, Expected Calibration Error (ECE)
â€¢ **Training callbacks** - Early stopping, learning rate reduction, checkpointing

### Explainability
â€¢ **Permutation importance** - OOF-based feature importance with confidence intervals
â€¢ **SHAP values** - Per-instance explanations with CSV export
â€¢ **Visualization notebooks** - Jupyter notebooks for feature analysis
â€¢ **Model-agnostic** - Works with any model type

### Model Serving
â€¢ **FastAPI REST API** - Production-ready inference server
â€¢ **Lazy TensorFlow loading** - Server starts in <1 second (TF loads on-demand)
â€¢ **Multi-model support** - TensorFlow SavedModel and sklearn (.pkl) models
â€¢ **Calibration in serving** - Automatic calibrated probability output
â€¢ **Batch predictions** - Multiple samples in single request

### Model Export
â€¢ **Complete artifact export** - SavedModel + calibrator + metadata
â€¢ **Version management** - Multiple model versions supported
â€¢ **Production-ready** - All artifacts needed for serving

---

## ðŸ“ Project Structure

```
ml_pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                    # Data loading and schema validation
â”‚   â”‚   â”œâ”€â”€ loader.py            # YAML schema-based data loader
â”‚   â”‚   â””â”€â”€ generate_sample.py   # Synthetic data generation
â”‚   â”œâ”€â”€ preprocessing/           # Preprocessing pipelines
â”‚   â”‚   â”œâ”€â”€ pipeline.py          # Full TensorFlow preprocessing
â”‚   â”‚   â””â”€â”€ lightweight_transformers.py  # Fast sklearn-only pipeline
â”‚   â”œâ”€â”€ models/                  # Model architectures
â”‚   â”‚   â”œâ”€â”€ tabular_ann.py       # ANN with embeddings
â”‚   â”‚   â”œâ”€â”€ train_utils.py        # Training utilities & callbacks
â”‚   â”‚   â””â”€â”€ export.py            # Model export utilities
â”‚   â”œâ”€â”€ training/                # Training orchestration
â”‚   â”‚   â””â”€â”€ cv.py                # KFold CV with nested HPO
â”‚   â”œâ”€â”€ metrics/                 # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ calibration.py       # Platt & Isotonic calibration
â”‚   â”‚   â””â”€â”€ eval.py              # ROC-AUC, PR-AUC, Brier, ECE
â”‚   â”œâ”€â”€ explainability/         # Model interpretability
â”‚   â”‚   â”œâ”€â”€ permutation.py       # Permutation importance
â”‚   â”‚   â””â”€â”€ shap.py              # SHAP value computation
â”‚   â”œâ”€â”€ baselines/               # Baseline models
â”‚   â”‚   â”œâ”€â”€ xgb_lgb.py           # XGBoost & LightGBM training
â”‚   â”‚   â””â”€â”€ compare_models.py    # Model comparison utilities
â”‚   â”œâ”€â”€ serve/                   # Model serving
â”‚   â”‚   â””â”€â”€ app.py               # FastAPI inference server
â”‚   â””â”€â”€ config/                   # Configuration
â”‚       â””â”€â”€ tf_config.py         # TensorFlow optimization
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb             # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_shap.ipynb            # SHAP explanations visualization
â”‚   â””â”€â”€ generate_plots.py        # Plot generation script
â”œâ”€â”€ tests/                       # Comprehensive test suite
â”‚   â”œâ”€â”€ test_loader.py           # Data loader tests
â”‚   â”œâ”€â”€ test_preprocessing.py    # Preprocessing tests
â”‚   â”œâ”€â”€ test_models.py           # Model architecture tests
â”‚   â”œâ”€â”€ test_cv.py               # Cross-validation tests
â”‚   â”œâ”€â”€ test_calibration.py     # Calibration tests
â”‚   â”œâ”€â”€ test_explainability.py   # Explainability tests
â”‚   â”œâ”€â”€ test_gbdt_baselines.py  # Baseline model tests
â”‚   â””â”€â”€ test_serve.py            # API serving tests
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ problem_spec.md          # Problem specification
â”‚   â”œâ”€â”€ data_contract.md         # Data contract & requirements
â”‚   â”œâ”€â”€ eda_summary.md           # EDA findings
â”‚   â”œâ”€â”€ comparison.md            # Model comparison guide
â”‚   â”œâ”€â”€ API_DOCUMENTATION.md     # Complete API reference
â”‚   â”œâ”€â”€ API_QUICK_REFERENCE.md   # Quick API cheat sheet
â”‚   â”œâ”€â”€ LIGHTWEIGHT_OPTIONS.md   # Lightweight deployment guide
â”‚   â””â”€â”€ PYTORCH_VS_TENSORFLOW.md # Framework comparison
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ schema.yaml              # Data schema definition
â”‚   â””â”€â”€ feature_list.csv         # Feature preprocessing decisions
â”œâ”€â”€ artifacts/                    # Model outputs
â”‚   â”œâ”€â”€ cv/                      # Cross-validation runs
â”‚   â””â”€â”€ models/                  # Exported models
â””â”€â”€ data/
    â””â”€â”€ sample.csv                # Sample dataset
```

---

## ðŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On macOS/Linux
# or: venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r requirements.txt

# Install lightweight TensorFlow (CPU-only, faster)
pip install tensorflow-cpu
```

### Run Preprocessing

```bash
# Lightweight pipeline (fast, no TF)
python -m src.preprocessing.lightweight_transformers

# Full pipeline (with TensorFlow)
python -m src.preprocessing.pipeline
```

### Train ANN Model

```bash
# Quick demo
python demo_ann_simple.py

# Full CV run
python -c "
from src.training.cv import run_kfold_cv
# ... load data and run CV
"
```

### Start API Server

```bash
# Start server (starts in <1 second)
./start_server.sh

# Or manually
uvicorn src.serve.app:app --host 0.0.0.0 --port 8000

# Load model and predict
curl -X POST "http://localhost:8000/load?model_dir=artifacts/models/champion"
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"features": [{"feature_0": 1.0, "feature_1": 2.0}]}'
```

---

## ðŸ“‹ Completed Tasks

### âœ… Task 1: Repository Skeleton + CI Basics
â€¢ Project structure with proper Python package layout
â€¢ Makefile for common tasks
â€¢ Requirements management
â€¢ Git workflow setup

### âœ… Task 2: Problem Specification & Data Contract
â€¢ `docs/problem_spec.md` - Complete problem definition
â€¢ `docs/data_contract.md` - Data requirements and temporal handling
â€¢ Schema definition in YAML format

### âœ… Task 3: Sample Dataset + Loader + Tests
â€¢ `src/data/loader.py` - Schema-based data loading
â€¢ `src/data/generate_sample.py` - Synthetic data generation
â€¢ `data/sample.csv` - 500-row sample dataset
â€¢ Comprehensive loader tests

### âœ… Task 4: EDA Notebook + Feature Decisions
â€¢ `notebooks/01_eda.ipynb` - Complete exploratory analysis
â€¢ `docs/eda_summary.md` - EDA findings summary
â€¢ `configs/feature_list.csv` - Feature preprocessing decisions
â€¢ Visualization plots (correlations, distributions, missing values)

### âœ… Task 5: Fold-Safe Preprocessing Pipeline
â€¢ `src/preprocessing/pipeline.py` - Full TensorFlow preprocessing
â€¢ `src/preprocessing/lightweight_transformers.py` - Fast sklearn pipeline
â€¢ Fold-safe design (fit on train, transform on val)
â€¢ Support for scale, one-hot, embedding strategies

### âœ… Task 6: ANN Baseline Model (Keras)
â€¢ `src/models/tabular_ann.py` - Tabular ANN with embeddings
â€¢ `src/models/train_utils.py` - Training utilities with callbacks
â€¢ Configurable architecture (layers, dropout, L2)
â€¢ Both probability and logit outputs

### âœ… Task 7: Cross-Validation & Nested CV
â€¢ `src/training/cv.py` - KFold CV with OOF predictions
â€¢ Optional inner-loop HPO (Grid/Random search)
â€¢ Per-fold artifacts (weights, metrics, normalizers)
â€¢ Reproducible with fixed seeds

### âœ… Task 8: Calibration & Evaluation Metrics
â€¢ `src/metrics/calibration.py` - Platt & Isotonic calibration
â€¢ `src/metrics/eval.py` - ROC-AUC, PR-AUC, Brier, ECE
â€¢ Automatic best calibrator selection
â€¢ Calibration curves and evaluation plots

### âœ… Task 9: Explainability (Permutation + SHAP)
â€¢ `src/explainability/permutation.py` - OOF-based permutation importance
â€¢ `src/explainability/shap.py` - SHAP value computation
â€¢ `notebooks/02_shap.ipynb` - Visualization notebook
â€¢ CSV export for external analysis

### âœ… Task 10: GBDT Baselines & Comparison
â€¢ `src/baselines/xgb_lgb.py` - XGBoost & LightGBM training
â€¢ Same CV splits as ANN for fair comparison
â€¢ Automatic calibration for GBDT models
â€¢ `docs/comparison.md` - Model comparison guide

### âœ… Task 11: Model Export & Serving
â€¢ `src/models/export.py` - Complete model export (SavedModel + calibrator)
â€¢ `src/serve/app.py` - FastAPI REST API server
â€¢ Lazy TensorFlow loading (server starts in <1s)
â€¢ Support for both TensorFlow and sklearn models

---

## ðŸ”§ Key Components

### Preprocessing Pipelines

**Lightweight Pipeline** (Fast, sklearn-only):
â€¢ `LightweightNumericTransformer` - Imputation + scaling
â€¢ `LightweightCategoricalTransformer` - One-hot encoding
â€¢ No TensorFlow dependency - perfect for fast iteration

**Full Pipeline** (TensorFlow):
â€¢ `NumericTransformer` - Keras Normalization layers
â€¢ `CategoricalTransformer` - StringLookup + embeddings
â€¢ Production-ready with full feature support

### Models

**TabularANN**:
â€¢ Input layers for each feature type
â€¢ Embedding layers for high-cardinality categoricals
â€¢ MLP trunk with dropout and L2 regularization
â€¢ Dual outputs: probabilities + logits (for calibration)

**XGBoost / LightGBM**:
â€¢ Same CV splits as ANN
â€¢ Automatic hyperparameter defaults
â€¢ Calibration support
â€¢ Fast training and inference

### Training Infrastructure

**Cross-Validation**:
â€¢ KFold with reproducible splits
â€¢ Optional nested CV for hyperparameter search
â€¢ Per-fold model artifacts
â€¢ OOF predictions for unbiased evaluation

**Callbacks**:
â€¢ EarlyStopping - Prevent overfitting
â€¢ ReduceLROnPlateau - Adaptive learning rate
â€¢ ModelCheckpoint - Save best models
â€¢ TrainingLogger - Console metrics

### Evaluation & Calibration

**Metrics**:
â€¢ ROC-AUC, PR-AUC (ranking metrics)
â€¢ Brier score (probability accuracy)
â€¢ Expected Calibration Error (ECE)
â€¢ Accuracy, Precision, Recall, F1

**Calibration**:
â€¢ Platt scaling (LogisticRegression on logits)
â€¢ Isotonic regression (non-parametric)
â€¢ Automatic best method selection

### Explainability

**Permutation Importance**:
â€¢ OOF-based (no model refitting needed)
â€¢ Multiple repeats for confidence intervals
â€¢ Feature ranking by importance

**SHAP Values**:
â€¢ KernelExplainer for model-agnostic explanations
â€¢ Per-instance feature contributions
â€¢ CSV export for visualization

### Serving

**FastAPI Server**:
â€¢ RESTful API with OpenAPI docs
â€¢ Multi-model support (TensorFlow + sklearn)
â€¢ Batch predictions
â€¢ Health checks and monitoring

---

## ðŸ“Š Performance Characteristics

### Startup Times
â€¢ **Server startup**: ~0.5 seconds (no TensorFlow)
â€¢ **Sklearn model load**: ~1-2 seconds
â€¢ **TensorFlow model load**: ~5-10 seconds (first time)
â€¢ **After first load**: Subsequent requests <50ms

### Model Training
â€¢ **Lightweight preprocessing**: <1 second for 500 samples
â€¢ **ANN training**: ~30-60 seconds per fold
â€¢ **XGBoost training**: ~5-15 seconds per fold
â€¢ **LightGBM training**: ~3-10 seconds per fold

### Memory Usage
â€¢ **Server (no model)**: ~50-100 MB
â€¢ **With sklearn model**: ~100-200 MB
â€¢ **With TensorFlow model**: ~300-500 MB

---

## ðŸ§ª Testing

### Run All Tests
```bash
pytest
```

### Run Specific Test Suites
```bash
# Data loading
pytest tests/test_loader.py

# Preprocessing
pytest tests/test_preprocessing.py
pytest tests/test_lightweight_preprocessing.py

# Models
pytest tests/test_models.py

# Cross-validation
pytest tests/test_cv.py

# Calibration
pytest tests/test_calibration.py

# Explainability
pytest tests/test_explainability.py

# GBDT baselines
pytest tests/test_gbdt_baselines.py

# API serving
pytest tests/test_serve.py
```

---

## ðŸ“š Documentation

| Document | Description |
|----------|-------------|
| `docs/problem_spec.md` | Problem definition and business requirements |
| `docs/data_contract.md` | Data schema and temporal handling |
| `docs/eda_summary.md` | Exploratory data analysis findings |
| `docs/comparison.md` | Model comparison guide (ANN vs XGB vs LGB) |
| `docs/API_DOCUMENTATION.md` | Complete API reference |
| `docs/API_QUICK_REFERENCE.md` | Quick API cheat sheet |
| `docs/LIGHTWEIGHT_OPTIONS.md` | Lightweight deployment options |
| `docs/PYTORCH_VS_TENSORFLOW.md` | Framework comparison |

---

## ðŸŽ¯ Usage Examples

### Complete Workflow

```python
# 1. Load data
from src.data.loader import DataLoader
loader = DataLoader("configs/schema.yaml")
df = loader.load_data("data/sample.csv")

# 2. Preprocess
from src.preprocessing.lightweight_transformers import create_lightweight_pipeline
pipeline = create_lightweight_pipeline()
pipeline.fit_on(df)
X, y = pipeline.transform(df)

# 3. Train with CV
from src.training.cv import run_kfold_cv
from src.models.tabular_ann import create_tabular_ann

feature_info = pipeline.get_feature_info()
summary = run_kfold_cv(
    X, y, feature_info,
    k_folds=5,
    seed=42,
    base_params={"epochs": 50, "batch_size": 64}
)

# 4. Export model
from src.models.export import export_from_cv_run
export_from_cv_run(
    cv_run_dir=summary["run_dir"],
    fold_idx=0,
    export_dir="artifacts/models/champion"
)

# 5. Serve model
# Start server: uvicorn src.serve.app:app --port 8000
# Load model via API and make predictions
```

### Model Comparison

```python
from src.baselines.xgb_lgb import run_gbdt_cv
from src.baselines.compare_models import compare_models

# Train GBDT baselines
gbdt_results = run_gbdt_cv(X, y, k_folds=5, seed=42)

# Compare all models
comparison = compare_models(
    ann_run_dir="artifacts/cv/ann_run",
    xgb_run_dir="artifacts/cv/gbdt_run"
)
print(comparison)
```

### Explainability

```python
from src.explainability.permutation import compute_permutation_importance_oof
from src.explainability.shap import compute_and_save_shap

# Load OOF predictions
oof_df = pd.read_csv("artifacts/cv/run_name/oof_predictions.csv")

# Permutation importance
perm_importance = compute_permutation_importance_oof(
    X, oof_df['y_true'], oof_df['oof_prob'],
    feature_names=feature_names
)

# SHAP values
shap_results = compute_and_save_shap(
    X[:100], model.predict_fn,
    output_path="artifacts/shap_values.csv"
)
```

---

## ðŸš€ Deployment

### Development
â€¢ Use lightweight preprocessing for fast iteration
â€¢ Sklearn models for quick baselines
â€¢ Jupyter notebooks for exploration

### Production
â€¢ Export models with complete artifacts
â€¢ Use FastAPI server with lazy loading
â€¢ Deploy with Docker (optional)
â€¢ Monitor with health checks

### Optimization Tips
â€¢ Use `tensorflow-cpu` for lighter installation
â€¢ Sklearn models for fastest serving
â€¢ Lazy TensorFlow loading (already implemented)
â€¢ Batch predictions for throughput

---

## ðŸ“¦ Dependencies

### Core
â€¢ **numpy, pandas** - Data manipulation
â€¢ **scikit-learn** - Preprocessing and baselines
â€¢ **tensorflow-cpu** - Neural network models (recommended)
â€¢ **fastapi, uvicorn** - API server

### Optional
â€¢ **xgboost, lightgbm** - GBDT baselines
â€¢ **shap** - SHAP explanations
â€¢ **matplotlib, seaborn** - Visualizations
â€¢ **jupyter** - Notebooks

See `requirements.txt` for complete list.

---

## ðŸ§ª Testing Status

âœ… **All test suites passing:**
â€¢ Data loading: âœ…
â€¢ Preprocessing: âœ…
â€¢ Models: âœ…
â€¢ Cross-validation: âœ…
â€¢ Calibration: âœ…
â€¢ Explainability: âœ…
â€¢ GBDT baselines: âœ… (requires xgboost/lightgbm)
â€¢ API serving: âœ…

---

## ðŸŽ“ Learning Resources

â€¢ **Problem Understanding**: `docs/problem_spec.md`
â€¢ **Data Contract**: `docs/data_contract.md`
â€¢ **EDA Analysis**: `notebooks/01_eda.ipynb`
â€¢ **SHAP Tutorial**: `notebooks/02_shap.ipynb`
â€¢ **API Guide**: `docs/API_DOCUMENTATION.md`

---

## ðŸ“ License

MIT License

---

## ðŸ™ Acknowledgments

Built as a complete ML pipeline demonstrating best practices for:
â€¢ Fold-safe preprocessing
â€¢ Multiple model architectures
â€¢ Comprehensive evaluation
â€¢ Model explainability
â€¢ Production serving

---

## ðŸ”— Quick Links

â€¢ [API Documentation](docs/API_DOCUMENTATION.md)
â€¢ [API Quick Reference](docs/API_QUICK_REFERENCE.md)
â€¢ [Model Comparison](docs/comparison.md)
â€¢ [Lightweight Options](docs/LIGHTWEIGHT_OPTIONS.md)
